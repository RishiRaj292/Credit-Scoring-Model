{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb96312-f329-4dd7-b42a-f700508c7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f94ba3f1-1357-4cd5-84ee-f7cfb800405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\nahso\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\nahso\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b828c1d2-bcc9-4bd2-be7b-78281ff62b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_excel('a_Dataset_CreditScoring.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df5840c-2ee1-4d62-ae61-6522569a831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To show the count of the number of rows and then columns (3000 rows and 30 columns)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d71bac-17cd-433a-ba46-3d91e3e3bfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>ID</th>\n",
       "      <th>DerogCnt</th>\n",
       "      <th>CollectCnt</th>\n",
       "      <th>BanruptcyInd</th>\n",
       "      <th>InqCnt06</th>\n",
       "      <th>InqTimeLast</th>\n",
       "      <th>InqFinanceCnt24</th>\n",
       "      <th>TLTimeFirst</th>\n",
       "      <th>TLTimeLast</th>\n",
       "      <th>...</th>\n",
       "      <th>TL50UtilCnt</th>\n",
       "      <th>TLBalHCPct</th>\n",
       "      <th>TLSatPct</th>\n",
       "      <th>TLDel3060Cnt24</th>\n",
       "      <th>TLDel90Cnt24</th>\n",
       "      <th>TLDel60CntAll</th>\n",
       "      <th>TLOpenPct</th>\n",
       "      <th>TLBadDerogCnt</th>\n",
       "      <th>TLDel60Cnt24</th>\n",
       "      <th>TLOpen24Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>582</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9179</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>662</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1175</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>130</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2511</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET    ID  DerogCnt  CollectCnt  BanruptcyInd  InqCnt06  InqTimeLast  \\\n",
       "0       1   582         3           3             0         4          0.0   \n",
       "1       1   662        15           9             0         3          1.0   \n",
       "2       1   805         0           0             0         1          5.0   \n",
       "3       1  1175         8           5             0         6          1.0   \n",
       "4       1  1373         3           1             0         9          0.0   \n",
       "\n",
       "   InqFinanceCnt24  TLTimeFirst  TLTimeLast  ...  TL50UtilCnt  TLBalHCPct  \\\n",
       "0                5          117          27  ...          3.0      0.9179   \n",
       "1                3           14          14  ...          1.0      0.8000   \n",
       "2                1          354           7  ...          5.0      0.3552   \n",
       "3               10           16           4  ...          3.0      0.9127   \n",
       "4                8          130          52  ...          1.0      1.2511   \n",
       "\n",
       "   TLSatPct  TLDel3060Cnt24  TLDel90Cnt24  TLDel60CntAll  TLOpenPct  \\\n",
       "0    0.2083               2             3              7     0.2083   \n",
       "1    0.0000               0             0              0     1.0000   \n",
       "2    0.6538               0             1              1     0.7308   \n",
       "3    0.2500               1             1              1     0.7500   \n",
       "4    0.0000               0             1              4     0.1429   \n",
       "\n",
       "   TLBadDerogCnt  TLDel60Cnt24  TLOpen24Pct  \n",
       "0              4             4       0.0000  \n",
       "1             12             0       1.0000  \n",
       "2              1             1       0.5263  \n",
       "3              7             1       1.3333  \n",
       "4              3             1       0.0000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To show the first few (first 5)records of the daatset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ded30c-6dc9-43dc-9464-daaf5fd385ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 29)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next , we drop the customer ID column from the dataset to make it more more relevant-\n",
    "dataset=dataset.drop('ID',axis=1)\n",
    "dataset.shape\n",
    "#We can see the number of columns changed from 30 to 29 , implying a column was discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ee5c18-6518-402c-92fc-5a8bb1096bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET               0\n",
       "DerogCnt             0\n",
       "CollectCnt           0\n",
       "BanruptcyInd         0\n",
       "InqCnt06             0\n",
       "InqTimeLast        188\n",
       "InqFinanceCnt24      0\n",
       "TLTimeFirst          0\n",
       "TLTimeLast           0\n",
       "TLCnt03              0\n",
       "TLCnt12              0\n",
       "TLCnt24              0\n",
       "TLCnt                3\n",
       "TLSum               40\n",
       "TLMaxSum            40\n",
       "TLSatCnt             4\n",
       "TLDel60Cnt           0\n",
       "TLBadCnt24           0\n",
       "TL75UtilCnt         99\n",
       "TL50UtilCnt         99\n",
       "TLBalHCPct          41\n",
       "TLSatPct             4\n",
       "TLDel3060Cnt24       0\n",
       "TLDel90Cnt24         0\n",
       "TLDel60CntAll        0\n",
       "TLOpenPct            3\n",
       "TLBadDerogCnt        0\n",
       "TLDel60Cnt24         0\n",
       "TLOpen24Pct          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next , we check the count for 'not available' values in the columns and return the number of such records(i.e. samples) for each column-\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71963657-0be1-468f-b2a2-6a1c624d7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we fill the missing values with mean -\n",
    "dataset=dataset.fillna(dataset.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a074b66-6493-49a4-935d-b8c362020c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET             0\n",
       "DerogCnt           0\n",
       "CollectCnt         0\n",
       "BanruptcyInd       0\n",
       "InqCnt06           0\n",
       "InqTimeLast        0\n",
       "InqFinanceCnt24    0\n",
       "TLTimeFirst        0\n",
       "TLTimeLast         0\n",
       "TLCnt03            0\n",
       "TLCnt12            0\n",
       "TLCnt24            0\n",
       "TLCnt              0\n",
       "TLSum              0\n",
       "TLMaxSum           0\n",
       "TLSatCnt           0\n",
       "TLDel60Cnt         0\n",
       "TLBadCnt24         0\n",
       "TL75UtilCnt        0\n",
       "TL50UtilCnt        0\n",
       "TLBalHCPct         0\n",
       "TLSatPct           0\n",
       "TLDel3060Cnt24     0\n",
       "TLDel90Cnt24       0\n",
       "TLDel60CntAll      0\n",
       "TLOpenPct          0\n",
       "TLBadDerogCnt      0\n",
       "TLDel60Cnt24       0\n",
       "TLOpen24Pct        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To see if our fix above was implemented correct , we again print the null 'not available' or 'na' values-\n",
    "#We see that indeed our fix worked , as no column is showing 'na' values now-\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f57570bf-71b6-4e85-b96c-22c90bf69c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW , WE SHALL DO THE TRAIN AND TEST SPLIT-\n",
    "y=dataset.iloc[:,0].values #we extract all the rows of the dataset for the target variable 'y' and the first column , then using the'.values' method , we convert them to Numpy array.\n",
    "#we only extracted the first row because that's how the dataset is structured , as the first column has the 'target' values( 0 or 1)\n",
    "x=dataset.iloc[:,1:29].values#we extract all the rows and the columns 1 to 28 from the dataset and convert them to numpy array and store then in this variable'x'.\n",
    "#we now have 'x' storing the rows as data points and each column as the feature using which prediction is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dafb7d0-c8be-4ca2-a633-664d7993e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "(3000, 28)\n"
     ]
    }
   ],
   "source": [
    "#Just to elaborate , the following shows the structure of the number of rows and columns in 'x' and 'y'-\n",
    "print(y.shape)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81a53a6e-da16-49f3-9e1d-3d70e80cda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now , we are going to split the dataset into training and testing (in ratio of 85:15)-\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5f351fe-05e6-40c6-b1e3-36b3caf22bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now , we perform z-score normalisation to better scale all the features and datapoints-=, using the Standardscaler class() from sklearn , or more specifically sklearn.preprocessing -\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b7b7660-44d8-4212-9fe9-4ef20488a66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\nahso\\\\PycharmProjects\\\\Credit Scoring Model\\\\futureuse_normalisation_creditscoring.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Savcing the normalisation coefficients and data for later use in prediction and future use-\n",
    "import joblib\n",
    "joblib.dump(sc, r'C:\\Users\\nahso\\PycharmProjects\\Credit Scoring Model\\futureuse_normalisation_creditscoring.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9ca51ee-2049-4fab-b540-92e199e1f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now , we do perform the classification action-\n",
    "\n",
    "classifier =  LogisticRegression()#This initialises an object 'classifier' from the sklearn library or the sklearn.linear_model , to be more specific\n",
    "classifier.fit(x_train, y_train)#This is to train the classifier object on  training data  ,as,x_train contains the feature data (independent variables) and y_train contains the corresponding labels/targets (dependent variable,here 0 or 1).\n",
    "#The fit method adjusts weights of the model and minimises the error in predicting y_train from x_train.It is a commonly used method\n",
    "y_pred = classifier.predict(x_test)#This uses the 'classifier' object to predict the labels or outputs 'y_pred' for a new set of data, i.e. test data , 'x_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c6fb0b1-c041-423c-b202-5ad9ac5674cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\nahso\\\\PycharmProjects\\\\Credit Scoring Model\\\\futureuse_Classifier_CreditScoring.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Logistic Regression Classifier for later implementation in prediction or future use-\n",
    "\n",
    "# import joblib, not required as already imported\n",
    "joblib.dump(classifier, r'C:\\Users\\nahso\\PycharmProjects\\Credit Scoring Model\\futureuse_Classifier_CreditScoring.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f443ef14-34a0-4a0b-bb51-acd8beb2f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[610  15]\n",
      " [104  21]]\n"
     ]
    }
   ],
   "source": [
    "# Model Performance will be judged .\n",
    "#Now , first we will print the confusion matrix-\n",
    "print(confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1c6babe-c8a2-4654-b5a3-637be275dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fractional accuracy is:0.8413333333333334\n",
      "The accuracy percentage is:84.13333333333334\n"
     ]
    }
   ],
   "source": [
    "#Now , we will print the accuracy of the model raw , then in percentage-\n",
    "\n",
    "print(f\"The fractional accuracy is:{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"The accuracy percentage is:{accuracy_score(y_test, y_pred)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbc6bf1f-6326-4dbd-938d-31fbc9765e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93243837, 0.06756163],\n",
       "       [0.91599714, 0.08400286],\n",
       "       [0.91140794, 0.08859206],\n",
       "       ...,\n",
       "       [0.88593837, 0.11406163],\n",
       "       [0.88062764, 0.11937236],\n",
       "       [0.53335147, 0.46664853]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, to print the probability score of each datapoint as an array, based on which creditworthiness was classified as yes/no or 1/0, and this is binary as Logistic Regression is involved-\n",
    "\n",
    "predictions = classifier.predict_proba(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f91deaa-767e-4df3-9890-c4a8a524197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Outcome</th>\n",
       "      <th>Probability 0</th>\n",
       "      <th>Probability 1</th>\n",
       "      <th>Predicted Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.932438</td>\n",
       "      <td>0.067562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.915997</td>\n",
       "      <td>0.084003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.911408</td>\n",
       "      <td>0.088592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.848250</td>\n",
       "      <td>0.151750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.809511</td>\n",
       "      <td>0.190489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual Outcome  Probability 0  Probability 1  Predicted Target\n",
       "0               1       0.932438       0.067562                 0\n",
       "1               0       0.915997       0.084003                 0\n",
       "2               0       0.911408       0.088592                 0\n",
       "3               0       0.848250       0.151750                 0\n",
       "4               0       0.809511       0.190489                 0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writing model output file\n",
    "\n",
    "df_pred_prob = pd.DataFrame(predictions, columns = ['Probability 0', 'Probability 1'])#This line creates a DataFrame from the 'predictions' array in the above cell, which contains the probabilities of each test sample belonging to class/category 0 and class/category 1. Columns are named 'Probability 0' and 'Probability 1'.\n",
    "\n",
    "df_pred_target = pd.DataFrame(classifier.predict(x_test), columns = ['Predicted Target'])#This creates another DataFrame from the 'predictions' made by the classifier (object) (i.e. class labels, not the probabilities), with a single column as 'Predicted Target'.\n",
    "\n",
    "df_test_dataset = pd.DataFrame(y_test,columns= ['Actual Outcome'])#This DataFrame is made from 'y_test, which contains the actual class 'labels' or 'mappings' for the test data, named 'Actual Outcome'.\n",
    "\n",
    "\n",
    "df_x=pd.concat([df_test_dataset, df_pred_prob, df_pred_target], axis=1)#This specific line concatenates the three DataFrames along the columns (axis=1), resulting in a single DataFrame 'df_x' that includes the actual outcomes, the predicted probabilities, and the predicted class labels for each test datapoint/sample.\n",
    "\n",
    "df_x.to_csv(r\"C:\\Users\\nahso\\PycharmProjects\\Credit Scoring Model\\Model_Prediction.csv\", sep=',', encoding='UTF-8')\n",
    "#This saves the DataFrame 'df_x' to a CSV file. The specific path and file name indicate it is saved as an 'Excel' file, but since the method 'to_csv' has been used,the file will actually be in CSV format, not XLSX.\n",
    "#So can also save it as '.csv' for more clarity.\n",
    "df_x.head()#To print the first few rows(5 specifically) of the merged dataframe-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08623e89-5545-4448-9b24-e6a483093726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have got the predictions for the credit scores now. For instance , out of the first 5 above, none of them are eligible for loans.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
